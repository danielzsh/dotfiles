snippet cpac
	#include <cassert>
	#include <iostream>
	#include <vector>
	#include <algorithm>
	#define int long long
	#define exit(X) { cout << (X); return; }
	using namespace std;
	using P = pair<int, int>;
	const int inf = 1e18;

	const int N = ${0};

	void ac() {

	}

	signed main() {
		cin.tie(0)->sync_with_stdio(0); 
		int t; cin >> t;
		while (t--) ac();
	}

snippet egcd
	// ---extended euclidean algorithm---
	int gcd(int a, int b, int& x, int& y) {
		x = 1, y = 0;
		int x1 = 0, y1 = 1, a1 = a, b1 = b;
		while (b1) {
			int q = a1 / b1;
			tie(x, x1) = make_tuple(x1, x - q * x1);
			tie(y, y1) = make_tuple(y1, y - q * y1);
			tie(a1, b1) = make_tuple(b1, a1 - q * b1);
		}
		return a1;
	}
	int gcd(int a, int b) { int x, y; return gcd(a, b, x, y); }

	int inv(int a, int m) {
		int x, y;
		gcd(a, m, x, y);
		return x % m;
	}

snippet phi
	// ---euler's totient funtion---
	int phi(int n) {
			int result = n;
			for (int i = 2; i * i <= n; i++) {
					if (n % i == 0) {
							while (n % i == 0)
									n /= i;
							result -= result / i;
					}
			}
			if (n > 1)
					result -= result / n;
			return result;
	}

snippet combo
	mint F[N], F_i[N];
	void pre(int n) { F[0] = F_i[0] = 1; for (int i = 1; i < n; i++) F_i[i] = (F[i] = F[i - 1] * i).inv(); }
	mint C(int n, int k) { return F[n] * F_i[n - k] * F_i[k]; }

snippet sieve
	bool np[N];
	void sieve() {
		for (int i = 2; i < N; i++) if (!np[i]) {
			for (int j = 2 * i; j < N; j += i) np[i] = true;
		}
	}

snippet dinic
	struct E {
		int y, id, cap;
	};
	vector<E> g[N * N];
	vector<E>::iterator e[N * N];

	void add_edge(int x, int y, int cap) {
		g[x].push_back({y, t++, cap});
		g[y].push_back({x, t++, 0});
	}

	bool bfs(int s, int t) {
		for (int i = 0; i <= t; i++) lv[i] = inf;
		queue<int> q;
		q.push(lv[s] = 0);
		while (q.size()) {
			int x = q.front(); q.pop();
			if (x == t) return true;
			for (auto [y, id, cap] : g[x]) if (cap > f[id] && lv[y] > lv[x] + 1) {
				lv[y] = lv[x] + 1; q.push(y);
			}
		}
		return false;
	}

	int dfs(int x, int fl, int t) {
		if (x == t) return fl;
		for (; e[x] != g[x].end(); e[x]++) {
			auto [y, id, cap] = *e[x];
			if (lv[y] != lv[x] + 1 || f[id] >= cap) continue; 
			int nf = dfs(y, min(fl, cap - f[id]), t);
			if (nf > 0) {
				f[id] += nf, f[id^1] -= nf;
				return nf;
			}
		}
		return 0;
	}

	int dinic(int s, int t) {
		int r = 0;
		while (bfs(s, t)) {
			for (int i = 0; i <= t; i++) e[i] = g[i].begin();
			while (int x = dfs(s, inf, t)) {
				r += x;
			}
		}
		return r;
	}

snippet randomac
	mt19937_64 rng(chrono::steady_clock::now().time_since_epoch().count());

snippet sparse
	int st[N][K];
	//---SPARSE TABLE---
	void build() {
		for (int i = 0; i < n; i++) st[i][0] = a[i];
		for (int k = 1; k < K; k++) for (int i = 0; i < n; i++) {
			st[i][k] = st[i][k - 1];
			if (int j = i + (1 << k - 1); j < n) st[i][k] = min(st[i][k], st[j][k - 1]);
		}
	}

	int mn(int l, int r) { // min on [l, r)
		int k = log2(r - l);
		return min(st[l][k], st[r - (1 << k)][k]);
	}
snippet matrix
	template <int... D> struct T {
		int v = 0;
		void operator*= (int x) { v = v * x % M; }
		void operator+= (int x) { v = ad(v, x); }
		void operator-= (int x) { v = sb(v, x); }
		void operator+= (T<> x) { *this += x.v; }
		void operator-= (T<> x) { *this -= x.v; }
		void operator= (int x) { v = x; }
		string str() { return to_string(v); }
	};
	template <int N, int... D> struct T<N, D...> {
		T<D...> a[N];
		T<N, D...> operator* (int v) {
			auto o = *this;
			for (int i = 0; i < N; i++) o[i] *= v;
			return o;
		}
		void operator*= (int v) { *this = *this * v; }
		T<N, D...> operator+ (T<N, D...> b) {
			auto o = *this;
			for (int i = 0; i < N; i++) o[i] += b[i];
			return o;
		}
		void operator+= (T<N, D...> b) { *this = *this + b; }
		void operator-= (T<N, D...> b) {
			for (int i = 0; i < N; i++) a[i] -= b[i];
		}
		T<D...>& operator[] (int i) { return a[i]; }
		string str() {
			string s = "";
			for (int i = 0; i < N; i++) s += a[i].str() + (sizeof...(D) ? "\n" : " ");
			return s;
		}
		void gauss(int n) {
			for (int i = 0; i <= n; i++) {
				if (!a[i][i].v) {
					int r = i; 
					for (int j = i + 1; j <= n; j++) if (a[j][i].v) r = j; 
					assert(a[r][i].v);
					swap(a[i], a[r]);
				}
				a[i] *= inv(a[i][i].v);
				for (int j = 0; j <= n; j++) if (j != i) {
					a[j] += a[i] * (M - a[j][i].v);
				}
			}
		}
	};

snippet mint
	struct mint;
	using P = pair<mint, mint>;
	struct mint {
		const static int M = ${0};
		int v = 0;
		mint() {}
		mint(int v) { this->v = (v % M + M) % M; }
		mint operator+(const mint &o) const { return v + o.v; }
		mint& operator+=(const mint& o) { v = (v + o.v) % M; return *this; }
		mint operator*(const mint &o) const { return v * o.v; }
		mint operator-(const mint &o) const { return v - o.v; }
		mint& operator-=(const mint& o) { mint t = v - o.v; v = t.v; return *this; }
		mint operator^(int y) const { mint r = 1, x = v; for (y <<= 1; y >>= 1; x = x * x) if (y & 1) r = r * x; return r; }
		mint inv() const { assert(v); return *this ^ M - 2; }
		mint sym() { return *this ^ (M - 1) / 2; } // legendre symbol: 1 -> qresidue, -1 -> non-residue
		friend istream& operator>>(istream& s, mint& v) { s >> v.v; return s; }
		friend ostream& operator<<(ostream& s, const mint& v) { s << v.v; return s; }
		mint sqrt() {
			if (!v) return 0;
			mint i = 1;
			while ((i * i - v).sym().v != M - 1) i = i + 1;
			mint w = i * i - v;
			auto mul = [&](P x, P y) { return P{
				x.first * y.first + x.second * y.second * w,
				x.first * y.second + x.second * y.first
			}; }; 
			P c = {i, 1}, r = {1, 0};
			for (int i = 1; i < 2 * M; i <<= 1) {
				if (((M + 1) / 2) & i) r = mul(r, c);
				c = mul(c, c);
			}
			assert(r.second.v == 0 && (r.first * r.first).v == v);
			if (r.first.v < M / 2) return r.first;
			return r.first * -1;
		}
		mint operator/(mint o) { return *this * o.inv(); }
	};

snippet vec
	struct V { mint u, v; mint& operator[](int i) { return i ? v : u; };
		V operator*(V o) { return {u * o.u, v * o.v}; }
		V operator*=(V o) { u *= o.u, v *= o.v; return *this; }
	}

snippet cht
	struct Line {
		mutable int k, m, p;
		bool operator<(const Line& o) const { return k < o.k; }
		bool operator<(int x) const { return p < x; }
	};

	struct LineContainer : multiset<Line, less<>> {
		// (for doubles, use inf = 1/.0, div(a,b) = a/b)
		int div(int a, int b) { // floored division
			return a / b - ((a ^ b) < 0 && a % b); }
		bool isect(iterator x, iterator y) {
			if (y == end()) return x->p = inf, 0;
			if (x->k == y->k) x->p = x->m > y->m ? inf : -inf;
			else x->p = div(y->m - x->m, x->k - y->k);
			return x->p >= y->p;
		}
		void add(int k, int m) {
			auto z = insert({k, m, 0}), y = z++, x = y;
			while (isect(y, z)) z = erase(z);
			if (x != begin() && isect(--x, y)) isect(x, y = erase(y));
			while ((y = x) != begin() && (--x)->p >= y->p)
				isect(x, erase(y));
		}
		// gets maximum
		int query(int x) {
			assert(!empty());
			auto l = *lower_bound(x);
			return l.k * x + l.m;
		}
	};

snippet sparse
	struct ST {
		bool mn;
		int st[N + 1][K]{};
		int f(int x, int y) {
			if (x < y) return mn ? x : y;
			else return mn ? y : x;
		}
		//---SPARSE TABLE---
		void build(vector<int> &a, bool m) { // m -> whether to use min(true) or max(false)
			mn = m;
			int n = a.size();
			for (int i = 0; i < n; i++) st[i][0] = a[i];
			for (int k = 1; k < K; k++) for (int i = 0; i < n; i++) {
				st[i][k] = st[i][k - 1];
				if (int j = i + (1 << k - 1); j < n) st[i][k] = f(st[i][k], st[j][k - 1]);
			}
		}
		int F(int l, int r) { // min on [l, r)
		if (l == r) return mn ? inf : -inf;
		int k = log2(r - l);
		return f(st[l][k], st[r - (1 << k)][k]);
		}
	};

